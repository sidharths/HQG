{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HvHzfCFEij7l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import datetime \n",
        "import torch\n",
        "from copy import deepcopy\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, get_linear_schedule_with_warmup, AdamW\n",
        "\n",
        "\n",
        "# Note: not only GPT2 \n",
        "def format_time(elapsed):\n",
        "    # print nicely formated elapsed time\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "\n",
        "class GPT2Dataset(Dataset):\n",
        "    \"\"\"\n",
        "    Pytorch Dataset wrapper that helps with training and batches of training data. Reads in texts of politicians\n",
        "    :param txt_list: (Numpy) array of speeches.\n",
        "    \"\"\"\n",
        "    def __init__(self, txt_list, tokenizer, max_length=768):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length=max_length\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "\n",
        "        for txt in txt_list:\n",
        "            encodings_dict = tokenizer(txt, truncation=True, max_length=self.max_length, padding=\"max_length\")\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx] \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GetData():\n",
        "    \"\"\"\n",
        "    Retrieve dataset from local or google colab. Helps generate pytorch dataloaders.\n",
        "    :param data_path: path to president_speeches file\n",
        "    :param token_length: Max token length to use in GPT2 model\n",
        "    \"\"\"\n",
        "    def __init__(self, token_length=768):\n",
        "        #self.data_path = data_path\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2', pad_token=\"<|endoftext|>\")\n",
        "         \n",
        "        self.speeches = self.read_data()\n",
        "        self.token_length = token_length\n",
        "\n",
        "        # after run once, keep as batch\n",
        "        self.dataset = None\n",
        "        self.dataloader = None \n",
        "\n",
        "    def read_data(self):\n",
        "        \"\"\"\n",
        "            Read data as pandas dataframe\n",
        "        \"\"\"\n",
        "        file1 = open('quotes.txt', 'r')\n",
        "        lines1 = [x[:-1] for x in file1.readlines()] \n",
        "        file1 = open('wikiquotes.txt', 'r')\n",
        "        lines2 = [x[:-1] for x in file1.readlines() if x and  x != \"\\n\"]\n",
        "        return lines1+lines2\n",
        "\n",
        "    def get_data(self):\n",
        "        \"\"\"\n",
        "            Return the dataset\n",
        "        \"\"\"\n",
        "        return self.speeches\n",
        "\n",
        "    def get_dataset(self, speech_list: list = None):\n",
        "        \"\"\"\n",
        "            Create a custom pytorch dataset specialised for this task. A customer speech list can be used as well.\n",
        "        \"\"\"\n",
        "        if speech_list is None:\n",
        "            speech_list = self.get_data()\n",
        "\n",
        "        self.dataset = GPT2Dataset(\n",
        "            txt_list=speech_list,\n",
        "            tokenizer=self.tokenizer,\n",
        "            max_length=self.token_length\n",
        "        )\n",
        "\n",
        "        return self.dataset\n",
        "\n",
        "    def get_dataloader(self, dataset: Dataset = None, batch_size=2):\n",
        "        \"\"\"\n",
        "            Create an iterable dataloader based on a GPT2Dataset and specified batch_size. Attention, a large batchsize quickly leads\n",
        "            to memory overloads.\n",
        "            :param dataset: Input GPT2Dataset object\n",
        "            :param batch_size: Integer of desired batch_size. Smaller equal 2 recommended.\n",
        "        \"\"\"\n",
        "        if dataset is None:\n",
        "            if self.dataset is None:\n",
        "                dataset = self.get_dataset()\n",
        "            else:\n",
        "                dataset = self.dataset\n",
        "\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            sampler=RandomSampler(dataset), # Select batches randomly\n",
        "            batch_size=batch_size # Trains with this batch size.\n",
        "        )\n",
        "        self.dataloader = dataloader\n",
        "        return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7dhsjX2rpAPF"
      },
      "outputs": [],
      "source": [
        "\n",
        "class HitchensQuoteModel(): \n",
        "    \n",
        "    def __init__(self, model_input: GPT2LMHeadModel = None, device=\"cuda\"):\n",
        "        self.device = device\n",
        "        self.device = torch.device(self.device)  # Sloppily use Cuda GPU. \n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2', pad_token=\"<|endoftext|>\")  # extract the gpt2 tokenizer\n",
        "        self.model = self.init_model(model_input=model_input)  # initiate model\n",
        "        self.model.to(self.device)  # send model to device\n",
        "\n",
        "\n",
        "    def init_model(self, model_input: GPT2LMHeadModel) -> GPT2LMHeadModel:\n",
        "        \"\"\"\n",
        "            Load pretrained model or use input model\n",
        "        \"\"\"\n",
        "        if model_input is None:\n",
        "            return GPT2LMHeadModel.from_pretrained(\"gpt2\",\n",
        "                                                    pad_token_id=self.tokenizer.eos_token_id)\n",
        "        else:\n",
        "            return model_input\n",
        "        \n",
        "\n",
        "    def fine_tune(self,\n",
        "                  data,\n",
        "                  epochs: int = 1,\n",
        "                  learning_rate: float = 5e-5,\n",
        "                  epsilon: float = 1e-8,\n",
        "                  warmup_steps: int = 100) -> None: \n",
        "        \n",
        "        # check input\n",
        "        assert type(data) == DataLoader, \"Datatype for 'data' must be DataLoader\"\n",
        "\n",
        "        # define implicite variables\n",
        "        batch_size = data.batch_size\n",
        "        total_steps = len(data) * epochs\n",
        "        sample_every = 20\n",
        "\n",
        "        # define optimizer\n",
        "        optimizer = AdamW(self.model.parameters(),\n",
        "                            lr=learning_rate,\n",
        "                            eps=epsilon)\n",
        "\n",
        "        # define scheduler for learningrate strategy\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                                    num_warmup_steps=warmup_steps, \n",
        "                                                    num_training_steps=total_steps)\n",
        "\n",
        "        self.model.train()  # put model in training mode (for dropout etc.)\n",
        "        \n",
        "        for epoch_i in range(0, epochs):\n",
        "            t0 = time.time()\n",
        "            for step, batch in enumerate(data):\n",
        "                # set batch values\n",
        "                b_input_ids = batch[0].to(self.device)\n",
        "                b_labels = batch[0].to(self.device)\n",
        "                b_masks = batch[1].to(self.device) \n",
        "                self.model.zero_grad() # reset gradients to not accumulate! \n",
        "\n",
        "                # forward propagation\n",
        "                outputs = self.model.forward( \n",
        "                    b_input_ids,\n",
        "                    labels=b_labels, \n",
        "                    #attention_mask = b_masks,\n",
        "                    token_type_ids=None)\n",
        "\n",
        "                # update params\n",
        "                loss = outputs[0]\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                batch_loss = loss.item()\n",
        "\n",
        "                # print in-between times\n",
        "                if step % sample_every == 0 and not step == 0:\n",
        "                    elapsed = format_time(time.time() - t0)\n",
        "                    print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(data), round(batch_loss, 4), elapsed))\n",
        "\n",
        "\n",
        "    def save_model(self, save_name): \n",
        "        self.model.save_pretrained(save_name)\n",
        "        \n",
        "      \n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "bc89a21329f74f3ba4176017d7401b58",
            "4b65d5c4a7fa4d00b7c15122c26b3e7c",
            "a0dd3e9b9e1f4ed886b724fd380f8c03",
            "75cde199a70b4f2f94cbfd9715b4a9a9",
            "3a6dc3a08f0048e5afcaedd2f8d7de6a",
            "536f2f57686f4d47ab1b51797947672c",
            "bcaefd1a119441559a8bc453c80bd72c",
            "c24d81c850a8451d8d79434a50d95215",
            "3bd46252ba764dc88abef28d02722c9d",
            "b50977792c864c9293667555766c4818",
            "f8d31ca6046e491fb03ff6044041ae1d",
            "ab7f860c88304385bfcb371b2d64c738",
            "9559e2962c2b414c87690fab780d1671",
            "d3c7076556b64fbea8ef0740ddbe2ea8",
            "7c52f1caf1a441ae8e83a6f2884898b6",
            "f8ab9cdea62c40cc9afd4bea65dc0edb"
          ]
        },
        "id": "VT4Q0AKUnUUA",
        "outputId": "a6700028-eb52-4329-c6e5-0be8d0a5aef8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "# load dataobject\n",
        "dt = GetData()\n",
        "\n",
        "mod = HitchensQuoteModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8kuDieZmUhh",
        "outputId": "b1bb615b-2277-40f6-cf10-d78fc0baa352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch    20  of    207. Loss: 0.9424.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.3891.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.1038.   Elapsed: 0:00:14.\n",
            "  Batch    80  of    207. Loss: 0.8286.   Elapsed: 0:00:18.\n",
            "  Batch   100  of    207. Loss: 0.209.   Elapsed: 0:00:23.\n",
            "  Batch   120  of    207. Loss: 0.1317.   Elapsed: 0:00:27.\n",
            "  Batch   140  of    207. Loss: 0.4562.   Elapsed: 0:00:32.\n",
            "  Batch   160  of    207. Loss: 0.4108.   Elapsed: 0:00:36.\n",
            "  Batch   180  of    207. Loss: 0.1435.   Elapsed: 0:00:41.\n",
            "  Batch   200  of    207. Loss: 0.4621.   Elapsed: 0:00:45.\n",
            "  Batch    20  of    207. Loss: 0.1434.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.2062.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.6976.   Elapsed: 0:00:14.\n",
            "  Batch    80  of    207. Loss: 0.0453.   Elapsed: 0:00:18.\n",
            "  Batch   100  of    207. Loss: 0.3644.   Elapsed: 0:00:23.\n",
            "  Batch   120  of    207. Loss: 0.187.   Elapsed: 0:00:27.\n",
            "  Batch   140  of    207. Loss: 0.1433.   Elapsed: 0:00:31.\n",
            "  Batch   160  of    207. Loss: 0.5221.   Elapsed: 0:00:35.\n",
            "  Batch   180  of    207. Loss: 0.5491.   Elapsed: 0:00:40.\n",
            "  Batch   200  of    207. Loss: 0.2098.   Elapsed: 0:00:44.\n",
            "  Batch    20  of    207. Loss: 0.3092.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.1216.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.1082.   Elapsed: 0:00:13.\n",
            "  Batch    80  of    207. Loss: 0.2203.   Elapsed: 0:00:17.\n",
            "  Batch   100  of    207. Loss: 0.2126.   Elapsed: 0:00:22.\n",
            "  Batch   120  of    207. Loss: 0.152.   Elapsed: 0:00:26.\n",
            "  Batch   140  of    207. Loss: 0.2334.   Elapsed: 0:00:30.\n",
            "  Batch   160  of    207. Loss: 0.055.   Elapsed: 0:00:35.\n",
            "  Batch   180  of    207. Loss: 0.4776.   Elapsed: 0:00:39.\n",
            "  Batch   200  of    207. Loss: 0.2339.   Elapsed: 0:00:43.\n",
            "  Batch    20  of    207. Loss: 0.3018.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.054.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.1662.   Elapsed: 0:00:13.\n",
            "  Batch    80  of    207. Loss: 0.1556.   Elapsed: 0:00:18.\n",
            "  Batch   100  of    207. Loss: 0.221.   Elapsed: 0:00:22.\n",
            "  Batch   120  of    207. Loss: 0.0926.   Elapsed: 0:00:26.\n",
            "  Batch   140  of    207. Loss: 0.0412.   Elapsed: 0:00:31.\n",
            "  Batch   160  of    207. Loss: 0.0724.   Elapsed: 0:00:35.\n",
            "  Batch   180  of    207. Loss: 0.376.   Elapsed: 0:00:40.\n",
            "  Batch   200  of    207. Loss: 0.1375.   Elapsed: 0:00:44.\n",
            "  Batch    20  of    207. Loss: 0.2738.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.148.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.0596.   Elapsed: 0:00:13.\n",
            "  Batch    80  of    207. Loss: 0.1221.   Elapsed: 0:00:18.\n",
            "  Batch   100  of    207. Loss: 0.1248.   Elapsed: 0:00:22.\n",
            "  Batch   120  of    207. Loss: 0.0696.   Elapsed: 0:00:27.\n",
            "  Batch   140  of    207. Loss: 0.217.   Elapsed: 0:00:32.\n",
            "  Batch   160  of    207. Loss: 0.1365.   Elapsed: 0:00:36.\n",
            "  Batch   180  of    207. Loss: 0.3324.   Elapsed: 0:00:41.\n",
            "  Batch   200  of    207. Loss: 0.1386.   Elapsed: 0:00:45.\n",
            "  Batch    20  of    207. Loss: 0.1703.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.036.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.0501.   Elapsed: 0:00:14.\n",
            "  Batch    80  of    207. Loss: 0.1905.   Elapsed: 0:00:19.\n",
            "  Batch   100  of    207. Loss: 0.1147.   Elapsed: 0:00:23.\n",
            "  Batch   120  of    207. Loss: 0.167.   Elapsed: 0:00:28.\n",
            "  Batch   140  of    207. Loss: 0.1763.   Elapsed: 0:00:32.\n",
            "  Batch   160  of    207. Loss: 0.2167.   Elapsed: 0:00:37.\n",
            "  Batch   180  of    207. Loss: 0.0183.   Elapsed: 0:00:41.\n",
            "  Batch   200  of    207. Loss: 0.0238.   Elapsed: 0:00:46.\n",
            "  Batch    20  of    207. Loss: 0.1097.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.0293.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.0338.   Elapsed: 0:00:14.\n",
            "  Batch    80  of    207. Loss: 0.0578.   Elapsed: 0:00:18.\n",
            "  Batch   100  of    207. Loss: 0.037.   Elapsed: 0:00:23.\n",
            "  Batch   120  of    207. Loss: 0.0371.   Elapsed: 0:00:27.\n",
            "  Batch   140  of    207. Loss: 0.0139.   Elapsed: 0:00:32.\n",
            "  Batch   160  of    207. Loss: 0.0698.   Elapsed: 0:00:36.\n",
            "  Batch   180  of    207. Loss: 0.0386.   Elapsed: 0:00:41.\n",
            "  Batch   200  of    207. Loss: 0.1691.   Elapsed: 0:00:45.\n",
            "  Batch    20  of    207. Loss: 0.0821.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.0481.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.0595.   Elapsed: 0:00:14.\n",
            "  Batch    80  of    207. Loss: 0.0492.   Elapsed: 0:00:18.\n",
            "  Batch   100  of    207. Loss: 0.0534.   Elapsed: 0:00:23.\n",
            "  Batch   120  of    207. Loss: 0.0897.   Elapsed: 0:00:27.\n",
            "  Batch   140  of    207. Loss: 0.0398.   Elapsed: 0:00:32.\n",
            "  Batch   160  of    207. Loss: 0.0218.   Elapsed: 0:00:36.\n",
            "  Batch   180  of    207. Loss: 0.1722.   Elapsed: 0:00:41.\n",
            "  Batch   200  of    207. Loss: 0.1225.   Elapsed: 0:00:46.\n",
            "  Batch    20  of    207. Loss: 0.1525.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.0483.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.0183.   Elapsed: 0:00:14.\n",
            "  Batch    80  of    207. Loss: 0.1201.   Elapsed: 0:00:18.\n",
            "  Batch   100  of    207. Loss: 0.0399.   Elapsed: 0:00:23.\n",
            "  Batch   120  of    207. Loss: 0.0187.   Elapsed: 0:00:28.\n",
            "  Batch   140  of    207. Loss: 0.1379.   Elapsed: 0:00:32.\n",
            "  Batch   160  of    207. Loss: 0.0228.   Elapsed: 0:00:38.\n",
            "  Batch   180  of    207. Loss: 0.0165.   Elapsed: 0:00:43.\n",
            "  Batch   200  of    207. Loss: 0.0151.   Elapsed: 0:00:49.\n",
            "  Batch    20  of    207. Loss: 0.0179.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.054.   Elapsed: 0:00:10.\n",
            "  Batch    60  of    207. Loss: 0.0294.   Elapsed: 0:00:14.\n",
            "  Batch    80  of    207. Loss: 0.0226.   Elapsed: 0:00:19.\n",
            "  Batch   100  of    207. Loss: 0.0229.   Elapsed: 0:00:23.\n",
            "  Batch   120  of    207. Loss: 0.0232.   Elapsed: 0:00:28.\n",
            "  Batch   140  of    207. Loss: 0.0197.   Elapsed: 0:00:33.\n",
            "  Batch   160  of    207. Loss: 0.0436.   Elapsed: 0:00:37.\n",
            "  Batch   180  of    207. Loss: 0.0198.   Elapsed: 0:00:42.\n",
            "  Batch   200  of    207. Loss: 0.135.   Elapsed: 0:00:46.\n",
            "  Batch    20  of    207. Loss: 0.0201.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.0192.   Elapsed: 0:00:10.\n",
            "  Batch    60  of    207. Loss: 0.0141.   Elapsed: 0:00:14.\n",
            "  Batch    80  of    207. Loss: 0.0141.   Elapsed: 0:00:19.\n",
            "  Batch   100  of    207. Loss: 0.0151.   Elapsed: 0:00:23.\n",
            "  Batch   120  of    207. Loss: 0.0541.   Elapsed: 0:00:28.\n",
            "  Batch   140  of    207. Loss: 0.0169.   Elapsed: 0:00:34.\n",
            "  Batch   160  of    207. Loss: 0.0125.   Elapsed: 0:00:39.\n",
            "  Batch   180  of    207. Loss: 0.0298.   Elapsed: 0:00:44.\n",
            "  Batch   200  of    207. Loss: 0.0448.   Elapsed: 0:00:49.\n",
            "  Batch    20  of    207. Loss: 0.0349.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.0127.   Elapsed: 0:00:10.\n",
            "  Batch    60  of    207. Loss: 0.0178.   Elapsed: 0:00:14.\n",
            "  Batch    80  of    207. Loss: 0.0112.   Elapsed: 0:00:19.\n",
            "  Batch   100  of    207. Loss: 0.0115.   Elapsed: 0:00:24.\n",
            "  Batch   120  of    207. Loss: 0.0083.   Elapsed: 0:00:28.\n",
            "  Batch   140  of    207. Loss: 0.0047.   Elapsed: 0:00:32.\n",
            "  Batch   160  of    207. Loss: 0.0153.   Elapsed: 0:00:37.\n",
            "  Batch   180  of    207. Loss: 0.0124.   Elapsed: 0:00:41.\n",
            "  Batch   200  of    207. Loss: 0.0129.   Elapsed: 0:00:46.\n",
            "  Batch    20  of    207. Loss: 0.0298.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.0076.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.006.   Elapsed: 0:00:13.\n",
            "  Batch    80  of    207. Loss: 0.0093.   Elapsed: 0:00:18.\n",
            "  Batch   100  of    207. Loss: 0.0141.   Elapsed: 0:00:22.\n",
            "  Batch   120  of    207. Loss: 0.0169.   Elapsed: 0:00:27.\n",
            "  Batch   140  of    207. Loss: 0.0111.   Elapsed: 0:00:32.\n",
            "  Batch   160  of    207. Loss: 0.0393.   Elapsed: 0:00:36.\n",
            "  Batch   180  of    207. Loss: 0.0289.   Elapsed: 0:00:41.\n",
            "  Batch   200  of    207. Loss:  0.01.   Elapsed: 0:00:46.\n",
            "  Batch    20  of    207. Loss: 0.0096.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.0139.   Elapsed: 0:00:10.\n",
            "  Batch    60  of    207. Loss: 0.0084.   Elapsed: 0:00:15.\n",
            "  Batch    80  of    207. Loss: 0.0185.   Elapsed: 0:00:19.\n",
            "  Batch   100  of    207. Loss: 0.0065.   Elapsed: 0:00:24.\n",
            "  Batch   120  of    207. Loss: 0.0101.   Elapsed: 0:00:28.\n",
            "  Batch   140  of    207. Loss: 0.0294.   Elapsed: 0:00:33.\n",
            "  Batch   160  of    207. Loss: 0.0265.   Elapsed: 0:00:37.\n",
            "  Batch   180  of    207. Loss: 0.0263.   Elapsed: 0:00:42.\n",
            "  Batch   200  of    207. Loss: 0.0118.   Elapsed: 0:00:46.\n",
            "  Batch    20  of    207. Loss: 0.0063.   Elapsed: 0:00:04.\n",
            "  Batch    40  of    207. Loss: 0.0078.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.0083.   Elapsed: 0:00:13.\n",
            "  Batch    80  of    207. Loss: 0.0104.   Elapsed: 0:00:17.\n",
            "  Batch   100  of    207. Loss: 0.0263.   Elapsed: 0:00:21.\n",
            "  Batch   120  of    207. Loss: 0.0074.   Elapsed: 0:00:25.\n",
            "  Batch   140  of    207. Loss: 0.0077.   Elapsed: 0:00:30.\n",
            "  Batch   160  of    207. Loss: 0.0159.   Elapsed: 0:00:35.\n",
            "  Batch   180  of    207. Loss: 0.0062.   Elapsed: 0:00:39.\n",
            "  Batch   200  of    207. Loss: 0.0055.   Elapsed: 0:00:44.\n",
            "  Batch    20  of    207. Loss: 0.0306.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.0089.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.0075.   Elapsed: 0:00:14.\n",
            "  Batch    80  of    207. Loss: 0.0079.   Elapsed: 0:00:19.\n",
            "  Batch   100  of    207. Loss: 0.0103.   Elapsed: 0:00:23.\n",
            "  Batch   120  of    207. Loss: 0.015.   Elapsed: 0:00:28.\n",
            "  Batch   140  of    207. Loss: 0.0085.   Elapsed: 0:00:32.\n",
            "  Batch   160  of    207. Loss: 0.0082.   Elapsed: 0:00:37.\n",
            "  Batch   180  of    207. Loss: 0.0148.   Elapsed: 0:00:42.\n",
            "  Batch   200  of    207. Loss: 0.0314.   Elapsed: 0:00:46.\n",
            "  Batch    20  of    207. Loss: 0.0095.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.0079.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.015.   Elapsed: 0:00:14.\n",
            "  Batch    80  of    207. Loss: 0.0194.   Elapsed: 0:00:18.\n",
            "  Batch   100  of    207. Loss: 0.0125.   Elapsed: 0:00:23.\n",
            "  Batch   120  of    207. Loss: 0.0035.   Elapsed: 0:00:27.\n",
            "  Batch   140  of    207. Loss: 0.0147.   Elapsed: 0:00:31.\n",
            "  Batch   160  of    207. Loss: 0.0099.   Elapsed: 0:00:36.\n",
            "  Batch   180  of    207. Loss: 0.0104.   Elapsed: 0:00:40.\n",
            "  Batch   200  of    207. Loss: 0.0054.   Elapsed: 0:00:44.\n",
            "  Batch    20  of    207. Loss: 0.0063.   Elapsed: 0:00:05.\n",
            "  Batch    40  of    207. Loss: 0.0172.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.0053.   Elapsed: 0:00:13.\n",
            "  Batch    80  of    207. Loss: 0.0178.   Elapsed: 0:00:18.\n",
            "  Batch   100  of    207. Loss: 0.0051.   Elapsed: 0:00:22.\n",
            "  Batch   120  of    207. Loss: 0.0141.   Elapsed: 0:00:26.\n",
            "  Batch   140  of    207. Loss: 0.0086.   Elapsed: 0:00:31.\n",
            "  Batch   160  of    207. Loss: 0.0225.   Elapsed: 0:00:35.\n",
            "  Batch   180  of    207. Loss: 0.0028.   Elapsed: 0:00:39.\n",
            "  Batch   200  of    207. Loss: 0.0058.   Elapsed: 0:00:44.\n",
            "  Batch    20  of    207. Loss:  0.02.   Elapsed: 0:00:04.\n",
            "  Batch    40  of    207. Loss: 0.0035.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.0059.   Elapsed: 0:00:13.\n",
            "  Batch    80  of    207. Loss: 0.0099.   Elapsed: 0:00:17.\n",
            "  Batch   100  of    207. Loss: 0.0097.   Elapsed: 0:00:22.\n",
            "  Batch   120  of    207. Loss: 0.0072.   Elapsed: 0:00:26.\n",
            "  Batch   140  of    207. Loss: 0.0095.   Elapsed: 0:00:31.\n",
            "  Batch   160  of    207. Loss: 0.0061.   Elapsed: 0:00:35.\n",
            "  Batch   180  of    207. Loss: 0.0039.   Elapsed: 0:00:39.\n",
            "  Batch   200  of    207. Loss: 0.014.   Elapsed: 0:00:43.\n",
            "  Batch    20  of    207. Loss: 0.0064.   Elapsed: 0:00:04.\n",
            "  Batch    40  of    207. Loss: 0.0067.   Elapsed: 0:00:09.\n",
            "  Batch    60  of    207. Loss: 0.0102.   Elapsed: 0:00:13.\n",
            "  Batch    80  of    207. Loss:  0.01.   Elapsed: 0:00:17.\n",
            "  Batch   100  of    207. Loss: 0.0105.   Elapsed: 0:00:21.\n",
            "  Batch   120  of    207. Loss: 0.0119.   Elapsed: 0:00:26.\n",
            "  Batch   140  of    207. Loss: 0.0069.   Elapsed: 0:00:30.\n",
            "  Batch   160  of    207. Loss: 0.0133.   Elapsed: 0:00:34.\n",
            "  Batch   180  of    207. Loss: 0.005.   Elapsed: 0:00:38.\n",
            "  Batch   200  of    207. Loss: 0.0068.   Elapsed: 0:00:43.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "all_loader = dt.get_dataloader()\n",
        "# train on  Hitchens quotes\n",
        "params = dict(\n",
        "    epochs=20,\n",
        "    learning_rate=2e-4,\n",
        "    epsilon = 1e-07\n",
        ")\n",
        "\n",
        "mod.fine_tune(all_loader, **params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "mod.save_model(\"hitch_gpt2\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "hitchens.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('venv': venv)",
      "name": "python385jvsc74a57bd0b8b57dfceea31b20adcfc17619e0dec71827d1de19fedaa08a84abb5b8410874"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a6dc3a08f0048e5afcaedd2f8d7de6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "3bd46252ba764dc88abef28d02722c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8d31ca6046e491fb03ff6044041ae1d",
              "IPY_MODEL_ab7f860c88304385bfcb371b2d64c738"
            ],
            "layout": "IPY_MODEL_b50977792c864c9293667555766c4818"
          }
        },
        "4b65d5c4a7fa4d00b7c15122c26b3e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536f2f57686f4d47ab1b51797947672c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75cde199a70b4f2f94cbfd9715b4a9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c24d81c850a8451d8d79434a50d95215",
            "placeholder": "​",
            "style": "IPY_MODEL_bcaefd1a119441559a8bc453c80bd72c",
            "value": " 665/665 [00:13&lt;00:00, 48.6B/s]"
          }
        },
        "7c52f1caf1a441ae8e83a6f2884898b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9559e2962c2b414c87690fab780d1671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "a0dd3e9b9e1f4ed886b724fd380f8c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_536f2f57686f4d47ab1b51797947672c",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a6dc3a08f0048e5afcaedd2f8d7de6a",
            "value": 665
          }
        },
        "ab7f860c88304385bfcb371b2d64c738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ab9cdea62c40cc9afd4bea65dc0edb",
            "placeholder": "​",
            "style": "IPY_MODEL_7c52f1caf1a441ae8e83a6f2884898b6",
            "value": " 548M/548M [00:11&lt;00:00, 45.7MB/s]"
          }
        },
        "b50977792c864c9293667555766c4818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc89a21329f74f3ba4176017d7401b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0dd3e9b9e1f4ed886b724fd380f8c03",
              "IPY_MODEL_75cde199a70b4f2f94cbfd9715b4a9a9"
            ],
            "layout": "IPY_MODEL_4b65d5c4a7fa4d00b7c15122c26b3e7c"
          }
        },
        "bcaefd1a119441559a8bc453c80bd72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c24d81c850a8451d8d79434a50d95215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c7076556b64fbea8ef0740ddbe2ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ab9cdea62c40cc9afd4bea65dc0edb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d31ca6046e491fb03ff6044041ae1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3c7076556b64fbea8ef0740ddbe2ea8",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9559e2962c2b414c87690fab780d1671",
            "value": 548118077
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}